{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spelling Recommender\n",
    "\n",
    "For this part of the assignment you will create three different spelling recommenders, that each take a list of misspelled words and recommends a correctly spelled word for every word in the list.\n",
    "\n",
    "For every misspelled word, the recommender should find find the word in `correct_spellings` that has the shortest distance*, and starts with the same letter as the misspelled word, and return that word as a recommendation.\n",
    "\n",
    "*Each of the three different recommenders will use a different distance measure (outlined below).\n",
    "\n",
    "Each of the recommenders should provide recommendations for the three default words provided: `['cormulent', 'incendenece', 'validrate']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import words\n",
    "#import nltk\n",
    "#nltk.download('words')\n",
    "correct_spellings = words.words()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "For this recommender, your function should provide recommendations for the three default words provided above using the following distance metric:\n",
    "\n",
    "**[Jaccard distance](https://en.wikipedia.org/wiki/Jaccard_index) on the trigrams of the two words.**\n",
    "\n",
    "*This function should return a list of length three:\n",
    "`['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:36: DeprecationWarning: generator 'ngrams' raised StopIteration\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['corpulent', 'indecence', 'validate']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_nine(entries=['cormulent', 'incendenece', 'validrate']):\n",
    "    \n",
    "    import nltk\n",
    "    from nltk.util import ngrams\n",
    "    from operator import itemgetter\n",
    "    nltk.download('words')\n",
    "    correct_spellings = words.words()\n",
    "    \n",
    "    a = entries[0]\n",
    "    finalList = []\n",
    "    \n",
    "    for i in range(0, len(entries)):\n",
    "        #list1 = list(entries[i])\n",
    "        word1 = entries[i]\n",
    "        jaccardList = []\n",
    "        \n",
    "        \n",
    "        w1 = word1[0]\n",
    "        correct_spellings2 = []\n",
    "        for z in range(0, len(correct_spellings)):\n",
    "            word2 = correct_spellings[z]\n",
    "            w2 = word2[0]\n",
    "            if w1.lower == w2.lower:\n",
    "                correct_spellings2.append(correct_spellings[z])\n",
    "        \n",
    "        \n",
    "        \n",
    "        for j in range(0, len(correct_spellings2)):\n",
    "            #list2 = list(correct_spellings[j])\n",
    "            word2 = correct_spellings2[j]\n",
    "            #intersection = len(list(set(list1).intersection(list2)))\n",
    "            #union = (len(list1) + len(list2)) - intersection\n",
    "            #dist = float(intersection / union)\n",
    "            \n",
    "            #calculate jaccard distance\n",
    "            dist = nltk.distance.jaccard_distance(set(nltk.ngrams(word1,n=3)),set(nltk.ngrams(word2,n=3)))\n",
    "            \n",
    "            jaccardList.append([correct_spellings2[j], dist])\n",
    "            \n",
    "            \n",
    "    \n",
    "        jaccardList = sorted(jaccardList, key=itemgetter(1), reverse=False)\n",
    "        finalList.append(jaccardList[0][0])\n",
    "        \n",
    "        \n",
    "    return finalList\n",
    "    \n",
    "answer_nine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "For this recommender, your function should provide recommendations for the three default words provided above using the following distance metric:\n",
    "\n",
    "**[Jaccard distance](https://en.wikipedia.org/wiki/Jaccard_index) on the 4-grams of the two words.**\n",
    "\n",
    "*This function should return a list of length three:\n",
    "`['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:31: DeprecationWarning: generator 'ngrams' raised StopIteration\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['cormus', 'incendiary', 'valid']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_ten(entries=['cormulent', 'incendenece', 'validrate']):\n",
    "    import nltk\n",
    "    from nltk.util import ngrams\n",
    "    from operator import itemgetter\n",
    "    nltk.download('words')\n",
    "    correct_spellings = words.words()\n",
    "    \n",
    "    a = entries[0]\n",
    "    finalList = []\n",
    "    \n",
    "    for i in range(0, len(entries)):\n",
    "        #list1 = list(entries[i])\n",
    "        word1 = entries[i]\n",
    "        jaccardList = []\n",
    "        \n",
    "        \n",
    "        w1 = word1[0]\n",
    "        correct_spellings2 = []\n",
    "        for z in range(0, len(correct_spellings)):\n",
    "            word2 = correct_spellings[z]\n",
    "            w2 = word2[0]\n",
    "            if w1.lower == w2.lower:\n",
    "                correct_spellings2.append(correct_spellings[z])\n",
    "        \n",
    "        \n",
    "        \n",
    "        for j in range(0, len(correct_spellings2)):\n",
    "            word2 = correct_spellings2[j]\n",
    "\n",
    "            #calculate jaccard distance\n",
    "            dist = nltk.distance.jaccard_distance(set(nltk.ngrams(word1,n=4)),set(nltk.ngrams(word2,n=4)))\n",
    "            \n",
    "            jaccardList.append([correct_spellings2[j], dist])\n",
    "            \n",
    "\n",
    "        jaccardList = sorted(jaccardList, key=itemgetter(1), reverse=False)\n",
    "        finalList.append(jaccardList[0][0])\n",
    "        \n",
    "        \n",
    "    return finalList\n",
    "    \n",
    "answer_ten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "For this recommender, your function should provide recommendations for the three default words provided above using the following distance metric:\n",
    "\n",
    "**[Edit distance on the two words with transpositions.](https://en.wikipedia.org/wiki/Damerau%E2%80%93Levenshtein_distance)**\n",
    "\n",
    "*This function should return a list of length three:\n",
    "`['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def answer_eleven(entries=['cormulent', 'incendenece', 'validrate']):\n",
    "    \n",
    "    \n",
    "    return # Your answer here \n",
    "    \n",
    "answer_eleven()"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-text-mining",
   "graded_item_id": "r35En",
   "launcher_item_id": "tCVfW",
   "part_id": "NTVgL"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
